{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple2layerNN_tensorflow_v1 .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3Kn5oeRSuE3fvUgMp14Hk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parastooAflaki/deeplearning/blob/master/simple2layerNN_tensorflow_v1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMaXHj5ASfG3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4bY_FmzSDug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "bcceaf97-bc85-4e0f-dfa3-66e43e75d2c0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFRDR8qWSIgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linearfunc():\n",
        "  X = tf.constant(np.random.randn(3,1),name = \"X\")\n",
        "  W = tf.constant(np.random.randn(4,3), name = \"W\")\n",
        "  b = tf.constant(np.random.randn(4,1),name=\"b\")\n",
        "  Y = tf.add(tf.matmul(W,X),b)\n",
        "\n",
        "  sess = tf.Session()\n",
        "  result = sess.run(Y)\n",
        "  sess.close()\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckRzeOy4TRFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "c145dfa5-7bab-4f9f-c1ad-6f98f6b1cf7c"
      },
      "source": [
        "print(str(linearfunc()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.08510042]\n",
            " [ 0.39044508]\n",
            " [ 1.80742228]\n",
            " [-3.33794844]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtscNIk6TY3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders (n_x , n_y):\n",
        "  #nx shape of image\n",
        "  #ny number of classes\n",
        "  X = tf.placeholder(dtype=float , shape = (n_x , None) , name = \"Placeholder_1\")\n",
        "  Y = tf.placeholder(dtype=float , shape = (n_y , None) , name = \"Placeholder_2\")\n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOFjOztXB4T1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b8c9643e-7ff4-441f-c7e2-8f1b2258b8df"
      },
      "source": [
        "X, Y = create_placeholders(12288, 6)\n",
        "print (\"X = \" + str(X))\n",
        "print (\"Y = \" + str(Y))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X = Tensor(\"Placeholder_1:0\", shape=(12288, ?), dtype=float32)\n",
            "Y = Tensor(\"Placeholder_2:0\", shape=(6, ?), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgNXckLrB_vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters():\n",
        " \n",
        "  W1 = tf.get_variable(name = \"W1\" , shape=[25,12288] , initializer=tf.contrib.layers.xavier_initializer())\n",
        "  b1 = tf.get_variable(\"b1\" , shape= [25 , 1] , initializer=tf.zeros_initializer())\n",
        "  W2 = tf.get_variable( \"W2\" , shape=[12,25] , initializer=tf.contrib.layers.xavier_initializer())\n",
        "  b2 = tf.get_variable(\"b2\" , shape= [12 , 1] , initializer=tf.zeros_initializer())\n",
        "  W3 = tf.get_variable(\"W3\" , shape=[6,12] , initializer=tf.contrib.layers.xavier_initializer())\n",
        "  b3 = tf.get_variable(\"b3\" , shape= [6 , 1] , initializer=tf.zeros_initializer())\n",
        "\n",
        "  parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "    \n",
        "  return parameters\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a-5lhwhEU5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "cbea1b71-5df6-4356-b60e-c4b38e3b9a69"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Session() as sess:  \n",
        "    parameters = initialize_parameters()\n",
        "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "    print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1 = <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref>\n",
            "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
            "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
            "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTbQUpNFE9IA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "  #the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "\n",
        "    Z1 = tf.add(tf.matmul(W1 , X) , b1)                                              # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2 , A1) , b2)                                              # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3 , A2) , b3) \n",
        "    return Z3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5etyhxqKNLdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dca936e0-18f1-4094-dfe2-4b8440f0bc1e"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Session() as sess:\n",
        "    X, Y = create_placeholders(12288, 6)\n",
        "    parameters = initialize_parameters()\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    print(\"Z3 = \" + str(Z3))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z3 = Tensor(\"Add_2:0\", shape=(6, ?), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onFGV81fNPnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(Z3, Y):\n",
        " \n",
        "    \n",
        "#   Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
        "#   Y -- \"true\" labels vector placeholder, same shape as Z3\n",
        "\n",
        "#    cost - Tensor of the cost function\n",
        "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
        "    logits = tf.transpose(Z3)\n",
        "    labels = tf.transpose(Y)\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels , logits=logits) )\n",
        " \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_4xyJXWPUeE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        " ''' \n",
        "    It is important to know that the \"logits\" and \"labels\" inputs of tf.nn.softmax_cross_entropy_with_logits are expected to be of shape (number of examples, num_classes). We have thus transposed Z3 and Y.\n",
        "    Besides, tf.reduce_mean basically does the summation over the examples.\n",
        "  '''\n",
        "\n",
        "\n",
        "After you compute the cost function. You will create an \"optimizer\" object. You have to call this object along with the cost when running the tf.session. When called, it will perform an optimization on the given cost with the chosen method and learning rate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_1VTQR_PVed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
        "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
        "    ops.reset_default_graph() \n",
        "    (n_x, m) = X_train.shape\n",
        "    n_y = Y_train.shape[0] \n",
        "    costs = []  \n",
        "\n",
        "    X, Y = create_placeholders(n_x , n_y)\n",
        "    parameters = initialize_parameters();\n",
        "    Z3 = forward_propagation(X , parameters= parameters)\n",
        "    cost = compute_cost(Z3 , Y)\n",
        "\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.0001 ).minimize(cost);\n",
        "\n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "            for minibatch in minibatches:\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
        "                _ , minibatch_cost = sess.run([optimizer , cost] , feed_dict= {X : minibatch_X , Y : minibatch_Y})\n",
        "                \n",
        "                epoch_cost += minibatch_cost / num_minibatches\n",
        "\n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "            parameters = sess.run(parameters)\n",
        "            print (\"Parameters have been trained!\")\n",
        "      \n",
        "      # lets save the parameters in a variable\n",
        "            parameters = sess.run(parameters)\n",
        "            print (\"Parameters have been trained!\")\n",
        "       \n",
        "        # Calculate the correct predictions\n",
        "            correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "            print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "            print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQkuo5-EWuG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WqWNqyHYAw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA0pbqYGYVPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}